from fastapi import FastAPI, UploadFile, File, HTTPException, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
import moviepy as mp
import cv2
import uvicorn
import os
import uuid
import shutil
import base64
import numpy as np
import psutil
import requests
import asyncio
import aiofiles
from datetime import datetime
from typing import List, Dict, Any
import json
import logging
from collections import OrderedDict
import gc
import math
import subprocess
import concurrent.futures
from threading import Thread
import queue
import time

# Ollama ì„±ëŠ¥ ìµœì í™” í™˜ê²½ë³€ìˆ˜ ì„¤ì • (í¬ë¡œìŠ¤ í”Œë«í¼)
def setup_ollama_environment():
    """í”Œë«í¼ë³„ Ollama í™˜ê²½ë³€ìˆ˜ ì„¤ì •"""
    import platform
    system = platform.system().lower()
    
    # ê³µí†µ ì„¤ì •
    os.environ['OLLAMA_NUM_PARALLEL'] = '1'  # ë‹¨ì¼ ëª¨ë¸ ì „ìš©
    os.environ['OLLAMA_MAX_LOADED_MODELS'] = '1'  # ë‹¨ì¼ ëª¨ë¸ ì§‘ì¤‘
    os.environ['OLLAMA_FLASH_ATTENTION'] = '1'
    os.environ['OLLAMA_KEEP_ALIVE'] = '15m'  # ëª¨ë¸ ìœ ì§€ ì‹œê°„
    os.environ['OLLAMA_GPU_LAYERS'] = '99'  # ëª¨ë“  ë ˆì´ì–´ë¥¼ GPUì—ì„œ ì²˜ë¦¬
    os.environ['OLLAMA_LOAD_TIMEOUT'] = '300'  # ë¡œë“œ íƒ€ì„ì•„ì›ƒ ì¦ê°€
    os.environ['OLLAMA_MAX_QUEUE'] = '5'  # ë‹¨ì¼ ëª¨ë¸ ìµœì í™” ëŒ€ê¸°ì—´
    os.environ['OLLAMA_CONTEXT_LENGTH'] = '8192'  # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì„¤ì •
    
    if system == 'darwin':  # macOS (M4 Max ìµœì í™”)
        os.environ['OLLAMA_NUM_GPU'] = '36'  # M4 Max 90% GPU ì‚¬ìš©
        os.environ['OLLAMA_GPU_MEMORY_FRACTION'] = '0.9'  # í†µí•© ë©”ëª¨ë¦¬ 90% í™œìš©
        # logger.info("macOS M4 Max Ollama í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ")
        
    elif system == 'windows':  # Windows
        os.environ['OLLAMA_NUM_GPU'] = '-1'  # ìë™ GPU ê°ì§€
        os.environ['OLLAMA_GPU_MEMORY_FRACTION'] = '0.8'  # Windows GPU ë©”ëª¨ë¦¬ 80%
        # logger.info("Windows Ollama í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ")
        
    elif system == 'linux':  # Linux
        os.environ['OLLAMA_NUM_GPU'] = '-1'  # ìë™ GPU ê°ì§€
        os.environ['OLLAMA_GPU_MEMORY_FRACTION'] = '0.8'  # Linux GPU ë©”ëª¨ë¦¬ 80%
        # logger.info("Linux Ollama í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ")

# Ollama í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì‹¤í–‰
setup_ollama_environment()

# ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
ANALYSIS_DIR = "analysis_results"
os.makedirs(ANALYSIS_DIR, exist_ok=True)

# ì‡¼ì¸  ì €ì¥ ë””ë ‰í† ë¦¬
SHORTS_DIR = "shorts"
os.makedirs(SHORTS_DIR, exist_ok=True)

# ì²­í¬ ì—…ë¡œë“œ ì„ì‹œ ë””ë ‰í† ë¦¬
TEMP_DIR = "temp"
os.makedirs(TEMP_DIR, exist_ok=True)

# ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = "uploads"
THUMBNAILS_DIR = "thumbnails"

def clear_directories():
    """ì—…ë¡œë“œ ë° ì¸ë„¤ì¼ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”"""
    print("Clearing upload and thumbnail directories...")
    
    # uploads í´ë” ë¹„ìš°ê¸°
    if os.path.exists(UPLOAD_DIR):
        for file in os.listdir(UPLOAD_DIR):
            file_path = os.path.join(UPLOAD_DIR, file)
            try:
                if os.path.isfile(file_path):
                    os.remove(file_path)
                    print(f"Removed upload file: {file}")
            except Exception as e:
                print(f"Error removing file {file}: {str(e)}")
    
    # thumbnails í´ë” ë¹„ìš°ê¸°
    if os.path.exists(THUMBNAILS_DIR):
        for file in os.listdir(THUMBNAILS_DIR):
            file_path = os.path.join(THUMBNAILS_DIR, file)
            try:
                if os.path.isfile(file_path):
                    os.remove(file_path)
                    print(f"Removed thumbnail: {file}")
            except Exception as e:
                print(f"Error removing thumbnail {file}: {str(e)}")

    # ë””ë ‰í† ë¦¬ ì¬ìƒì„±
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    os.makedirs(THUMBNAILS_DIR, exist_ok=True)
    print("Directories cleared and recreated.")

# ì„œë²„ ì‹œì‘ ì‹œ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
clear_directories()

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="EODI Video Analysis API",
    description="ë¹„ë””ì˜¤ ë¶„ì„ ë° ì‡¼ì¸  ìƒì„±ì„ ìœ„í•œ API",
    version="1.0.0"
)

# ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸ (ì¸ë„¤ì¼ ì œê³µìš©)
app.mount("/thumbnails", StaticFiles(directory=THUMBNAILS_DIR), name="thumbnails")

# CORS ì„¤ì • (Electron ì•±ê³¼ì˜ í†µì‹ ì„ ìœ„í•´)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ë°°í¬ì‹œ íŠ¹ì • originìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
ANALYSIS_DIR = "analysis_results"
os.makedirs(ANALYSIS_DIR, exist_ok=True)

# ì‡¼ì¸  ì €ì¥ ë””ë ‰í† ë¦¬
SHORTS_DIR = "shorts"
os.makedirs(SHORTS_DIR, exist_ok=True)

# ì²­í¬ ì—…ë¡œë“œ ì„ì‹œ ë””ë ‰í† ë¦¬
TEMP_DIR = "temp"
os.makedirs(TEMP_DIR, exist_ok=True)

# ì¸ë„¤ì¼ ì €ì¥ ë””ë ‰í† ë¦¬
THUMBNAILS_DIR = "thumbnails"
os.makedirs(THUMBNAILS_DIR, exist_ok=True)

# ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì €ì¥ (ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ ì €ì¥ì†Œ - ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ê¶Œì¥)
videos_db = []

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
RESULTS_DIR = "temp"
os.makedirs(RESULTS_DIR, exist_ok=True)

class BatchSizeManager:
    """ë™ì  ë°°ì¹˜ í¬ê¸° ê´€ë¦¬"""
    def __init__(self, min_batch=2, max_batch=8, target_memory_usage=0.8):
        self.min_batch = min_batch
        self.max_batch = max_batch
        self.target_memory_usage = target_memory_usage
        self.current_batch_size = 4  # GPU ê°€ì†ì„ ê³ ë ¤í•œ ê¸°ë³¸ê°’
        
    def get_optimal_batch_size(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°"""
        try:
            memory = psutil.virtual_memory()
            available_memory_gb = memory.available / (1024**3)
            
            # M4 Max í†µí•© ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
            if available_memory_gb > 20:
                optimal_batch = 12  # M4 Max ê³ ì„±ëŠ¥ (í†µí•© ë©”ëª¨ë¦¬ ìµœì í™”)
            elif available_memory_gb > 15:
                optimal_batch = 10  # ë†’ì€ ì„±ëŠ¥
            elif available_memory_gb > 10:
                optimal_batch = 8   # ì¤‘ê³ ì„±ëŠ¥
            elif available_memory_gb > 5:
                optimal_batch = 6   # ì¤‘ì„±ëŠ¥
            else:
                optimal_batch = 4   # ì•ˆì •ì„± ìš°ì„ 
                
            self.current_batch_size = min(
                max(self.min_batch, optimal_batch),
                self.max_batch
            )
            
            logger.info(f"Available memory: {available_memory_gb:.1f}GB, Batch size: {self.current_batch_size}")
            return self.current_batch_size
            
        except Exception as e:
            logger.warning(f"ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨, ê¸°ë³¸ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©: {e}")
            return self.current_batch_size

class OptimizedFrameExtractor:
    """M4 Max ìµœì í™”ëœ ê³ ì† í”„ë ˆì„ ì¶”ì¶œê¸°"""
    
    def __init__(self, target_size=(640, 360)):
        self.target_size = target_size
        self.max_workers = 4  # CPU ì½”ì–´ í™œìš©
        self.platform = os.name
    
    def _get_hwaccel_args(self):
        """OSë³„ FFmpeg í•˜ë“œì›¨ì–´ ê°€ì† ì¸ìˆ˜ ë°˜í™˜"""
        import platform
        system = platform.system().lower()
        
        if system == 'darwin':  # macOS
            return ['-hwaccel', 'videotoolbox']
        elif system == 'windows':  # Windows
            # NVIDIA GPUê°€ ìˆëŠ” ê²½ìš° NVENC ì‚¬ìš©
            try:
                # GPU í™•ì¸ (ê°„ë‹¨í•œ ë°©ë²•)
                result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    logger.info("NVIDIA GPU ê°ì§€, NVENC í•˜ë“œì›¨ì–´ ê°€ì† ì‚¬ìš©")
                    return ['-hwaccel', 'cuda', '-hwaccel_output_format', 'cuda']
            except:
                pass
            
            # DirectX Video Acceleration (DXVA2) ì‚¬ìš© (Intel/AMD GPU)
            logger.info("Windows DXVA2 í•˜ë“œì›¨ì–´ ê°€ì† ì‚¬ìš©")
            return ['-hwaccel', 'dxva2']
            
        elif system == 'linux':  # Linux
            # VAAPI (Intel/AMD) ë˜ëŠ” VDPAU (NVIDIA) ì‚¬ìš©
            try:
                # NVIDIA GPU í™•ì¸
                result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    logger.info("Linux NVIDIA GPU ê°ì§€, CUDA í•˜ë“œì›¨ì–´ ê°€ì† ì‚¬ìš©")
                    return ['-hwaccel', 'cuda']
            except:
                pass
            
            logger.info("Linux VAAPI í•˜ë“œì›¨ì–´ ê°€ì† ì‚¬ìš©")
            return ['-hwaccel', 'vaapi']
        
        # ê¸°ë³¸ê°’: ì†Œí”„íŠ¸ì›¨ì–´ ë””ì½”ë”©
        logger.info("í•˜ë“œì›¨ì–´ ê°€ì† ë¯¸ì§€ì›, ì†Œí”„íŠ¸ì›¨ì–´ ë””ì½”ë”© ì‚¬ìš©")
        return []
    
    def _get_opencv_backend(self):
        """OSë³„ OpenCV ë°±ì—”ë“œ ë°˜í™˜"""
        import platform
        system = platform.system().lower()
        
        if system == 'darwin':  # macOS
            return cv2.CAP_AVFOUNDATION
        elif system == 'windows':  # Windows
            return cv2.CAP_DSHOW  # DirectShow
        elif system == 'linux':  # Linux
            return cv2.CAP_V4L2   # Video4Linux2
        else:
            return cv2.CAP_ANY    # ê¸°ë³¸ê°’
        
    def extract_frames_ffmpeg_hardware(self, video_path, interval_seconds=1):
        """FFmpeg í•˜ë“œì›¨ì–´ ê°€ì†ìœ¼ë¡œ í”„ë ˆì„ ì¶”ì¶œ (í¬ë¡œìŠ¤ í”Œë«í¼)"""
        try:
            # OSë³„ í•˜ë“œì›¨ì–´ ê°€ì† ì„¤ì •
            hwaccel_args = self._get_hwaccel_args()
            
            cmd = [
                'ffmpeg',
                *hwaccel_args,  # OSë³„ í•˜ë“œì›¨ì–´ ê°€ì†
                '-i', video_path,
                '-vf', f'fps=1/{interval_seconds},scale={self.target_size[0]}:{self.target_size[1]}',
                '-f', 'image2pipe',
                '-pix_fmt', 'rgb24',
                '-vcodec', 'rawvideo',
                '-loglevel', 'quiet',  # ë¡œê·¸ ìµœì†Œí™”
                '-'
            ]
            
            logger.info(f"FFmpeg í•˜ë“œì›¨ì–´ ê°€ì† í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘: {video_path}")
            start_time = time.time()
            
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            frames_data = []
            frame_count = 0
            
            # í”„ë ˆì„ í¬ê¸° ê³„ì‚°
            frame_size = self.target_size[0] * self.target_size[1] * 3  # RGB
            
            while True:
                # í”„ë ˆì„ ë°ì´í„° ì½ê¸°
                raw_frame = process.stdout.read(frame_size)
                if len(raw_frame) != frame_size:
                    break
                    
                # numpy ë°°ì—´ë¡œ ë³€í™˜
                frame = np.frombuffer(raw_frame, dtype=np.uint8)
                frame = frame.reshape((self.target_size[1], self.target_size[0], 3))
                
                # BGRë¡œ ë³€í™˜ (OpenCV í˜¸í™˜)
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                
                timestamp = frame_count * interval_seconds
                frames_data.append({
                    'frame': frame_bgr,
                    'timestamp': timestamp
                })
                frame_count += 1
            
            process.wait()
            extraction_time = time.time() - start_time
            logger.info(f"FFmpeg ì¶”ì¶œ ì™„ë£Œ: {frame_count}ê°œ í”„ë ˆì„, {extraction_time:.2f}ì´ˆ")
            
            return frames_data
            
        except Exception as e:
            logger.warning(f"FFmpeg í•˜ë“œì›¨ì–´ ê°€ì† ì‹¤íŒ¨, OpenCVë¡œ í´ë°±: {e}")
            return self.extract_frames_opencv_optimized(video_path, interval_seconds)
    
    def extract_frames_opencv_optimized(self, video_path, interval_seconds=1):
        """OpenCV ìµœì í™” í”„ë ˆì„ ì¶”ì¶œ (í¬ë¡œìŠ¤ í”Œë«í¼ í´ë°±)"""
        logger.info(f"OpenCV ìµœì í™” í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘: {video_path}")
        start_time = time.time()
        
        # OSë³„ OpenCV ë°±ì—”ë“œ ì„¤ì •
        backend = self._get_opencv_backend()
        cap = cv2.VideoCapture(video_path, backend)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ ìµœì†Œí™”
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_interval = max(1, int(fps * interval_seconds))
        
        frames_data = []
        
        # í•„ìš”í•œ í”„ë ˆì„ë§Œ ì§ì ‘ ì í”„í•˜ì—¬ ì¶”ì¶œ
        for frame_num in range(0, total_frames, frame_interval):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
            ret, frame = cap.read()
            
            if ret:
                # ì¶”ì¶œê³¼ ë™ì‹œì— ë¦¬ì‚¬ì´ì§•
                frame_resized = cv2.resize(frame, self.target_size, 
                                         interpolation=cv2.INTER_LINEAR)
                
                timestamp = frame_num / fps
                frames_data.append({
                    'frame': frame_resized,
                    'timestamp': timestamp
                })
        
        cap.release()
        extraction_time = time.time() - start_time
        logger.info(f"OpenCV ì¶”ì¶œ ì™„ë£Œ: {len(frames_data)}ê°œ í”„ë ˆì„, {extraction_time:.2f}ì´ˆ")
        
        return frames_data
    
    def extract_frames_parallel(self, video_path, timestamps):
        """ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ íŠ¹ì • íƒ€ì„ìŠ¤íƒ¬í”„ í”„ë ˆì„ë“¤ ë³‘ë ¬ ì¶”ì¶œ"""
        logger.info(f"ë³‘ë ¬ í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘: {len(timestamps)}ê°œ íƒ€ì„ìŠ¤íƒ¬í”„")
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [
                executor.submit(self._extract_single_frame, video_path, timestamp) 
                for timestamp in timestamps
            ]
            
            frames_data = []
            for i, future in enumerate(concurrent.futures.as_completed(futures)):
                try:
                    frame_data = future.result()
                    if frame_data:
                        frames_data.append(frame_data)
                except Exception as e:
                    logger.error(f"í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨ (timestamp {timestamps[i]}): {e}")
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœìœ¼ë¡œ ì •ë ¬
        frames_data.sort(key=lambda x: x['timestamp'])
        
        extraction_time = time.time() - start_time
        logger.info(f"ë³‘ë ¬ ì¶”ì¶œ ì™„ë£Œ: {len(frames_data)}ê°œ í”„ë ˆì„, {extraction_time:.2f}ì´ˆ")
        
        return frames_data
    
    def _extract_single_frame(self, video_path, timestamp):
        """ë‹¨ì¼ í”„ë ˆì„ ì¶”ì¶œ (ìŠ¤ë ˆë“œìš©)"""
        try:
            cap = cv2.VideoCapture(video_path)
            cap.set(cv2.CAP_PROP_POS_MSEC, timestamp * 1000)
            ret, frame = cap.read()
            cap.release()
            
            if ret:
                frame_resized = cv2.resize(frame, self.target_size, 
                                         interpolation=cv2.INTER_LINEAR)
                return {
                    'frame': frame_resized,
                    'timestamp': timestamp
                }
        except Exception as e:
            logger.error(f"ë‹¨ì¼ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨ (timestamp {timestamp}): {e}")
        
        return None

class SceneAnalyzer:
    """ì¥ë©´ ë¶„ì„ê¸° - ìµœì í™”ëœ í”„ë ˆì„ ì¶”ì¶œ í†µí•©"""
    def __init__(self, scene_threshold=0.65):
        self.scene_threshold = scene_threshold
        self.frame_extractor = OptimizedFrameExtractor(target_size=(640, 360))  # ìµœì í™”ëœ ì¶”ì¶œê¸°
        # ë‹¨ì¼ Ollama ì„œë²„ URL
        self.ollama_url = "http://127.0.0.1:11434/api/generate"
        self.interval_seconds = 1.0
        self.video_duration = 0.0
        
    def get_ollama_url(self):
        """ë‹¨ì¼ Ollama ì„œë²„ URL ë°˜í™˜"""
        return self.ollama_url
        
    async def extract_frames_from_video(self, video_path, interval_seconds=2):
        """ìµœì í™”ëœ í”„ë ˆì„ ì¶”ì¶œ (FFmpeg í•˜ë“œì›¨ì–´ ê°€ì† ìš°ì„ )"""
        try:
            # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¨¼ì € ê°€ì ¸ì˜¤ê¸°
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps
            cap.release()
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.interval_seconds = float(interval_seconds)
            self.video_duration = float(duration)
            
            logger.info(f"ë¹„ë””ì˜¤ ì •ë³´: FPS={fps}, ì´ í”„ë ˆì„={total_frames}, ê¸¸ì´={duration:.1f}ì´ˆ")
            logger.info("ğŸš€ ìµœì í™”ëœ í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘ (FFmpeg í•˜ë“œì›¨ì–´ ê°€ì† ìš°ì„ )")
            
            # FFmpeg í•˜ë“œì›¨ì–´ ê°€ì†ìœ¼ë¡œ í”„ë ˆì„ ì¶”ì¶œ ì‹œë„
            raw_frames = self.frame_extractor.extract_frames_ffmpeg_hardware(
                video_path, interval_seconds
            )
            
            # Base64 ì¸ì½”ë”© (Ollama ì „ì†¡ìš©)
            frames_data = []
            for frame_data in raw_frames:
                frame = frame_data['frame']
                timestamp = frame_data['timestamp']
                
                # JPEG í’ˆì§ˆ ìµœì í™” (70 í’ˆì§ˆë¡œ ì†ë„ì™€ í’ˆì§ˆ ê· í˜•)
                _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
                img_base64 = base64.b64encode(buffer).decode('utf-8')
                
                frames_data.append({
                    'timestamp': timestamp,
                    'frame_index': int(timestamp * fps),
                    'image_base64': img_base64
                })
                
                if len(frames_data) % 10 == 0:  # 10ê°œë§ˆë‹¤ ë¡œê·¸
                    logger.info(f"í”„ë ˆì„ ì¸ì½”ë”© ì§„í–‰: {len(frames_data)}ê°œ ì™„ë£Œ")
            
            logger.info(f"ğŸ¯ ìµœì í™”ëœ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ: {len(frames_data)}ê°œ í”„ë ˆì„")
            return frames_data
            
        except Exception as e:
            logger.error(f"ìµœì í™”ëœ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def detect_scene_changes(self, frames_data):
        """ê°œì„ ëœ ì¥ë©´ ì „í™˜ ê°ì§€ - êµ¬ë„ ë³€í™” vs ì‹¤ì œ ì¥ë©´ ë³€í™” êµ¬ë¶„"""
        scene_changes = [0]  # ì²« ë²ˆì§¸ í”„ë ˆì„ì€ í•­ìƒ ìƒˆë¡œìš´ ì¥ë©´
        
        try:
            prev_hist = None
            prev_frame = None
            consecutive_changes = 0  # ì—°ì† ë³€í™” ì¹´ìš´í„°
            
            for i, frame_data in enumerate(frames_data):
                # base64ì—ì„œ ì´ë¯¸ì§€ ë³µì›
                img_data = base64.b64decode(frame_data['image_base64'])
                nparr = np.frombuffer(img_data, np.uint8)
                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                
                if prev_hist is not None and prev_frame is not None:
                    # 1. íˆìŠ¤í† ê·¸ë¨ ë¹„êµ (ìƒ‰ìƒ ë¶„í¬)
                    hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
                    color_correlation = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)
                    
                    # 2. êµ¬ì¡°ì  ìœ ì‚¬ë„ ë¹„êµ (SSIM - êµ¬ë„/í˜•íƒœ ë³€í™”)
                    gray_current = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    gray_prev = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
                    
                    # ê°„ë‹¨í•œ êµ¬ì¡°ì  ìœ ì‚¬ë„ ê³„ì‚° (SSIM ëŒ€ì‹  í…œí”Œë¦¿ ë§¤ì¹­ ì‚¬ìš©)
                    result = cv2.matchTemplate(gray_current, gray_prev, cv2.TM_CCOEFF_NORMED)
                    structural_similarity = np.max(result)
                    
                    # 3. ë³µí•© íŒë‹¨ ê¸°ì¤€
                    is_scene_change = False
                    
                    # ìƒ‰ìƒê³¼ êµ¬ì¡° ëª¨ë‘ í¬ê²Œ ë³€í•œ ê²½ìš° (ì‹¤ì œ ì¥ë©´ ì „í™˜)
                    if color_correlation < self.scene_threshold and structural_similarity < 0.5:
                        is_scene_change = True
                        change_reason = "ìƒ‰ìƒ+êµ¬ì¡° ë³€í™”"
                    
                    # ìƒ‰ìƒì€ ìœ ì‚¬í•˜ì§€ë§Œ êµ¬ì¡°ê°€ í¬ê²Œ ë³€í•œ ê²½ìš° (ì¹´ë©”ë¼ ì•µê¸€ ë³€í™”)
                    elif color_correlation > 0.8 and structural_similarity < 0.3:
                        is_scene_change = True
                        change_reason = "êµ¬ì¡°ì  ë³€í™”"
                    
                    # ìƒ‰ìƒì´ í¬ê²Œ ë³€í–ˆì§€ë§Œ êµ¬ì¡°ëŠ” ìœ ì‚¬í•œ ê²½ìš° (ì¡°ëª… ë³€í™” - ì¥ë©´ ì „í™˜ ì•„ë‹˜)
                    elif color_correlation < 0.5 and structural_similarity > 0.7:
                        is_scene_change = False
                        change_reason = "ì¡°ëª… ë³€í™” (ë¬´ì‹œ)"
                    
                    # ì—°ì†ì ì¸ ì‘ì€ ë³€í™” ê°ì§€ (ì ì§„ì  ì¥ë©´ ì „í™˜)
                    if color_correlation < 0.75:
                        consecutive_changes += 1
                    else:
                        consecutive_changes = 0
                    
                    # ì—°ì† 3íšŒ ì´ìƒ ë³€í™” ì‹œ ì¥ë©´ ì „í™˜ìœ¼ë¡œ íŒë‹¨
                    if consecutive_changes >= 3:
                        is_scene_change = True
                        change_reason = "ì ì§„ì  ë³€í™”"
                        consecutive_changes = 0
                    
                    if is_scene_change:
                        scene_changes.append(i)
                        logger.info(f"ì¥ë©´ ì „í™˜ ê°ì§€: {frame_data['timestamp']:.1f}ì´ˆ - {change_reason} "
                                  f"(ìƒ‰ìƒ: {color_correlation:.3f}, êµ¬ì¡°: {structural_similarity:.3f})")
                    else:
                        logger.debug(f"ì¥ë©´ ìœ ì§€: {frame_data['timestamp']:.1f}ì´ˆ - {change_reason} "
                                   f"(ìƒ‰ìƒ: {color_correlation:.3f}, êµ¬ì¡°: {structural_similarity:.3f})")
                
                # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚° (ë‹¤ìŒ ë¹„êµìš©)
                hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
                prev_hist = hist
                prev_frame = frame.copy()
            
            return scene_changes
            
        except Exception as e:
            logger.error(f"ì¥ë©´ ì „í™˜ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            return [0]
    
    def group_frames_by_scene(self, frames_data, scene_changes):
        """í”„ë ˆì„ì„ ì¥ë©´ë³„ë¡œ ê·¸ë£¹í™”"""
        scenes = []
        
        for i in range(len(scene_changes)):
            start_idx = scene_changes[i]
            end_idx = scene_changes[i + 1] if i + 1 < len(scene_changes) else len(frames_data)
            
            scene_frames = frames_data[start_idx:end_idx]
            if scene_frames:
                scenes.append({
                    'scene_id': i + 1,
                    'start_time': scene_frames[0]['timestamp'],
                    'end_time': scene_frames[-1]['timestamp'],
                    'frames': scene_frames
                })
        
        logger.info(f"ì´ {len(scenes)}ê°œ ì¥ë©´ìœ¼ë¡œ ë¶„í• ")
        return scenes
    
    async def analyze_scene_batch(self, scene_frames, scene_id, start_time, end_time):
        """ì¥ë©´ì˜ ë°°ì¹˜ ë¶„ì„"""
        try:
            # ëŒ€í‘œ í”„ë ˆì„ ì„ íƒ (ìµœëŒ€ 3ê°œ)
            representative_frames = self.select_representative_frames(scene_frames)
            
            # ë” ë³µì¡í•œ GPU ì§‘ì•½ì  ë¶„ì„ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ì¥ë©´ {scene_id} ì¢…í•© ë¶„ì„ ({start_time:.1f}ì´ˆ ~ {end_time:.1f}ì´ˆ):

ì´ ì¥ë©´ì˜ ëª¨ë“  í”„ë ˆì„ì„ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ëª¨ë“  í•­ëª©ì„ í¬í•¨í•œ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

{{
    "scene_description": "ì¥ë©´ì˜ ë§¤ìš° ìƒì„¸í•œ ì„¤ëª… (ìµœì†Œ 100ì)",
    "visual_elements": {{
        "objects": ["ì‹ë³„ëœ ëª¨ë“  ê°ì²´ë“¤"],
        "colors": ["ì£¼ìš” ìƒ‰ìƒë“¤ê³¼ ìƒ‰ì¡° ë¶„ì„"],
        "lighting": "ì¡°ëª… ìƒíƒœì™€ ê·¸ë¦¼ì ë¶„ì„",
        "composition": "í™”ë©´ êµ¬ì„±ê³¼ ë ˆì´ì•„ì›ƒ ë¶„ì„"
    }},
    "mood": "ì£¼ìš” ë¶„ìœ„ê¸° (happy/sad/excited/calm/tense/peaceful/dramatic/mysterious ì¤‘ í•˜ë‚˜)",
    "emotion_intensity": 0.0~1.0 ì‚¬ì´ì˜ ê°ì • ê°•ë„,
    "situation": "ìƒí™©ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…",
    "key_events": ["ì¥ë©´ì—ì„œ ì¼ì–´ë‚˜ëŠ” ëª¨ë“  ì£¼ìš” ì‚¬ê±´ë“¤"],
    "character_analysis": {{
        "people_count": "ë“±ì¥ì¸ë¬¼ ìˆ˜",
        "expressions": ["í‘œì • ë¶„ì„"],
        "actions": ["í–‰ë™ ë¶„ì„"],
        "interactions": ["ìƒí˜¸ì‘ìš© ë¶„ì„"]
    }},
    "technical_analysis": {{
        "camera_movement": "ì¹´ë©”ë¼ ì›€ì§ì„ ë¶„ì„",
        "shot_type": "ìƒ·ì˜ ì¢…ë¥˜ (í´ë¡œì¦ˆì—…, ë¡±ìƒ· ë“±)",
        "focus_area": "ì´ˆì ì´ ë§ì¶°ì§„ ì˜ì—­"
    }},
    "highlight_score": 0.0~1.0 ì‚¬ì´ì˜ í•˜ì´ë¼ì´íŠ¸ ì ìˆ˜,
    "mood_progression": "ì¥ë©´ ë‚´ ë¶„ìœ„ê¸° ë³€í™”ì˜ ìƒì„¸ ë¶„ì„",
    "narrative_importance": "ìŠ¤í† ë¦¬í…”ë§ ê´€ì ì—ì„œì˜ ì¤‘ìš”ë„ ë¶„ì„"
}}

ëª¨ë“  í”„ë ˆì„ì˜ ì—°ì†ì„±, ì‹œê°ì  ìš”ì†Œ, ê°ì •ì  íë¦„ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
            
            # ì´ë¯¸ì§€ë“¤ì„ Ollamaì— ì „ì†¡
            images = [frame['image_base64'] for frame in representative_frames]
            
            response = await self.call_ollama_api(prompt, images)
            
            if response:
                return self.parse_analysis_response(response, scene_id, start_time, end_time)
            else:
                return self.create_fallback_analysis(scene_id, start_time, end_time)
                
        except Exception as e:
            logger.error(f"ì¥ë©´ {scene_id} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self.create_fallback_analysis(scene_id, start_time, end_time)
    
    def select_representative_frames(self, scene_frames):
        """ì¥ë©´ì˜ ëŒ€í‘œ í”„ë ˆì„ ì„ íƒ"""
        if len(scene_frames) <= 3:
            return scene_frames
        
        # ì ì ˆí•œ ëŒ€í‘œ í”„ë ˆì„ ì„ íƒ (ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ ê· í˜•)
        frame_count = min(3, len(scene_frames))  # ìµœëŒ€ 3ê°œ í”„ë ˆì„ (ì•ˆì •ì„±)
        indices = []
        
        for i in range(frame_count):
            idx = int(i * (len(scene_frames) - 1) / (frame_count - 1))
            indices.append(idx)
        
        return [scene_frames[i] for i in indices]
    
    async def call_ollama_api(self, prompt, images):
        """Ollama API í˜¸ì¶œ"""
        try:
            payload = {
                "model": "qwen2.5vl:7b",
                "prompt": prompt,
                "images": images,
                "stream": False,
                "keep_alive": "10m",  # ëª¨ë¸ì„ 10ë¶„ê°„ ë©”ëª¨ë¦¬ì— ìœ ì§€
                "options": {
                    "temperature": 0.3,
                    "top_p": 0.9,
                    "num_gpu": 36,  # 90% GPU í™œìš©ë¥  ëª©í‘œ (40ì½”ì–´ * 0.9)
                    "num_thread": 10,  # CPU ìŠ¤ë ˆë“œ ì ì ˆíˆ ì¡°ì •
                    "num_ctx": 7168,   # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° 90% í™œìš©
                    "num_batch": 896,  # ë°°ì¹˜ í¬ê¸° 90% í™œìš©
                    "num_predict": 360, # ì˜ˆì¸¡ í† í° 90% í™œìš©
                    "repeat_penalty": 1.1,
                    "top_k": 40,
                    "num_keep": 4,  # ë” ë§ì€ í† í° ìœ ì§€
                    "tfs_z": 1.0,  # ì¶”ê°€ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
                    "typical_p": 1.0  # ì¶”ê°€ ì²˜ë¦¬ ë¶€í•˜
                }
            }
            
            logger.info("Ollama API í˜¸ì¶œ ì¤‘...")
            
            async with asyncio.timeout(60):  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ (ë³µì¡í•œ ë¶„ì„ìš©)
                # ë¹„ë™ê¸° HTTP ìš”ì²­ì„ ìœ„í•´ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                loop = asyncio.get_event_loop()
                # ë‹¨ì¼ ì„œë²„ URL ì‚¬ìš©
                ollama_url = self.get_ollama_url()
                response = await loop.run_in_executor(
                    None,  # ê¸°ë³¸ ThreadPoolExecutor ì‚¬ìš©
                    lambda: requests.post(
                        ollama_url,
                        json=payload,
                        timeout=60
                    )
                )
                
                if response.status_code == 200:
                    result = response.json()
                    response_text = result.get('response', '')
                    logger.info(f"Ollama ë¶„ì„ ì™„ë£Œ - ì‘ë‹µ ê¸¸ì´: {len(response_text)}")
                    if not response_text:
                        logger.warning("Ollama ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
                    return response_text
                else:
                    logger.error(f"Ollama API HTTP ì˜¤ë¥˜: {response.status_code}, ì‘ë‹µ: {response.text[:200]}")
                    return None
                    
        except asyncio.TimeoutError:
            logger.error(f"Ollama API íƒ€ì„ì•„ì›ƒ (60ì´ˆ ì´ˆê³¼): {ollama_url}")
            return None
        except requests.exceptions.ConnectionError as e:
            logger.error(f"Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {ollama_url} - ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
            return None
        except Exception as e:
            logger.error(f"Ollama API í˜¸ì¶œ ì‹¤íŒ¨ - URL: {ollama_url}, ì˜¤ë¥˜: {str(e)}, íƒ€ì…: {type(e)}")
            return None
    
    def parse_analysis_response(self, response_text, scene_id, start_time, end_time):
        """Ollama ì‘ë‹µ íŒŒì‹± - ì¤‘ì²© JSON êµ¬ì¡° í•´ê²°"""
        try:
            logger.info(f"ì¥ë©´ {scene_id} ì‘ë‹µ íŒŒì‹± ì‹œì‘ - ê¸¸ì´: {len(response_text) if response_text else 0}")
            
            if not response_text:
                logger.error(f"ì¥ë©´ {scene_id}: ë¹ˆ ì‘ë‹µ")
                return self.create_fallback_analysis(scene_id, start_time, end_time)
            
            # ë‹¤ì–‘í•œ JSON ì¶”ì¶œ ë°©ë²• ì‹œë„
            analysis = None
            
            # ë°©ë²• 1: í‘œì¤€ JSON ë¸”ë¡ ì¶”ì¶œ
            if '{' in response_text and '}' in response_text:
                try:
                    start = response_text.find('{')
                    end = response_text.rfind('}') + 1
                    json_str = response_text[start:end]
                    analysis = json.loads(json_str)
                    logger.info(f"ì¥ë©´ {scene_id}: í‘œì¤€ JSON íŒŒì‹± ì„±ê³µ")
                except json.JSONDecodeError as e:
                    logger.warning(f"ì¥ë©´ {scene_id}: í‘œì¤€ JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")
            
            # ë°©ë²• 2: ì¤‘ì²©ëœ JSON ë¬¸ìì—´ ì²˜ë¦¬
            if not analysis and 'scene_description' in response_text:
                try:
                    # scene_descriptionì´ JSON ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                    import re
                    nested_json_match = re.search(r'"scene_description":\s*"({.*?})"', response_text, re.DOTALL)
                    if nested_json_match:
                        nested_json_str = nested_json_match.group(1).replace('\n', '').replace('\\', '')
                        analysis = json.loads(nested_json_str)
                        logger.info(f"ì¥ë©´ {scene_id}: ì¤‘ì²© JSON íŒŒì‹± ì„±ê³µ")
                except Exception as e:
                    logger.warning(f"ì¥ë©´ {scene_id}: ì¤‘ì²© JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")
            
            # ë°©ë²• 3: ë¶€ë¶„ ì •ë³´ ì¶”ì¶œ
            if not analysis:
                try:
                    # ê¸°ë³¸ êµ¬ì¡°ë¡œ ì•ˆì „í•˜ê²Œ íŒŒì‹±
                    analysis = {
                        "scene_description": self._extract_description(response_text),
                        "mood": self._extract_field(response_text, "mood", "neutral"),
                        "emotion_intensity": float(self._extract_field(response_text, "emotion_intensity", "0.5")),
                        "situation": self._extract_field(response_text, "situation", "ì¼ë°˜ì ì¸ ìƒí™©"),
                        "key_events": [],
                        "highlight_score": float(self._extract_field(response_text, "highlight_score", "0.5")),
                        "mood_progression": self._extract_field(response_text, "mood_progression", "ì•ˆì •ì ")
                    }
                    logger.info(f"ì¥ë©´ {scene_id}: ë¶€ë¶„ ì •ë³´ ì¶”ì¶œ ì„±ê³µ")
                except Exception as e:
                    logger.warning(f"ì¥ë©´ {scene_id}: ë¶€ë¶„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ - {e}")
            
            # ìµœì¢… ê²€ì¦ ë° ì •ë¦¬
            if analysis:
                # scene_descriptionì´ JSON ë¬¸ìì—´ì¸ ê²½ìš° ì‹¤ì œ ì„¤ëª…ë§Œ ì¶”ì¶œ
                if isinstance(analysis.get('scene_description'), str):
                    desc = analysis['scene_description']
                    if desc.startswith('{') and desc.endswith('}'):
                        try:
                            nested = json.loads(desc)
                            if 'scene_description' in nested:
                                analysis['scene_description'] = nested['scene_description']
                        except:
                            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì²« 200ìë§Œ ì‚¬ìš©
                            analysis['scene_description'] = desc[:200] + "..." if len(desc) > 200 else desc
                
                # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                analysis.update({
                    "scene_id": scene_id,
                    "time_range": {
                        "start": int(start_time),
                        "end": int(end_time),
                        "duration": int(end_time - start_time)
                    },
                    "timestamp": datetime.now().isoformat()
                })
                
                logger.info(f"ì¥ë©´ {scene_id}: íŒŒì‹± ì™„ë£Œ - {analysis['mood']}")
                return analysis
            
            # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ í´ë°±
            logger.error(f"ì¥ë©´ {scene_id}: ëª¨ë“  íŒŒì‹± ë°©ë²• ì‹¤íŒ¨")
            return self.create_fallback_analysis(scene_id, start_time, end_time)
            
        except Exception as e:
            logger.error(f"ì¥ë©´ {scene_id} íŒŒì‹± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
            if response_text:
                logger.error(f"ì‘ë‹µ ë‚´ìš© ìƒ˜í”Œ: {response_text[:100]}...")
            return self.create_fallback_analysis(scene_id, start_time, end_time)
    
    def _extract_description(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ ì¥ë©´ ì„¤ëª… ì¶”ì¶œ"""
        # JSON ë‚´ë¶€ì˜ scene_description ì°¾ê¸°
        import re
        desc_match = re.search(r'"scene_description":\s*"([^"]*)"', text)
        if desc_match:
            return desc_match.group(1)
        
        # ì¼ë°˜ í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ ì¶”ì¶œ
        if len(text) > 200:
            return text[:200] + "..."
        return text
    
    def _extract_field(self, text, field_name, default_value):
        """í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • í•„ë“œ ê°’ ì¶”ì¶œ"""
        import re
        pattern = rf'"{field_name}":\s*"?([^",\}}]*)"?'
        match = re.search(pattern, text)
        if match:
            value = match.group(1).strip('"')
            return value if value else default_value
        return default_value
    
    def create_fallback_analysis(self, scene_id, start_time, end_time):
        """ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
        return {
            "scene_id": scene_id,
            "scene_description": f"ì¥ë©´ {scene_id} - ë¶„ì„ ì‹¤íŒ¨",
            "mood": "unknown",
            "emotion_intensity": 0.0,
            "situation": "ë¶„ì„ ë¶ˆê°€",
            "key_events": [],
            "highlight_score": 0.0,
            "mood_progression": "ì•Œ ìˆ˜ ì—†ìŒ",
            "time_range": {
                "start": start_time,
                "end": end_time,
                "duration": end_time - start_time
            },
            "timestamp": datetime.now().isoformat(),
            "error": True
        }

def extract_video_metadata(file_path):
    """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°(ê¸¸ì´, ì¸ë„¤ì¼) ì¶”ì¶œ"""
    try:
        # ë¹„ë””ì˜¤ ê¸¸ì´ ì¶”ì¶œ
        video = mp.VideoFileClip(file_path)
        duration = int(video.duration)
        video.close()

        # ì¸ë„¤ì¼ ìƒì„± (ì²« í”„ë ˆì„)
        cap = cv2.VideoCapture(file_path)
        ret, frame = cap.read()
        
        thumbnail_path = None
        if ret:
            thumbnail_filename = f"thumb_{os.path.basename(file_path)}.jpg"
            thumbnail_path = os.path.join(THUMBNAILS_DIR, thumbnail_filename)
            cv2.imwrite(thumbnail_path, frame)
            # ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            thumbnail_path = f"/thumbnails/{thumbnail_filename}"
            
        cap.release()

        return {
            "duration": format_duration(duration),
            "thumbnail": thumbnail_path
        }
    except Exception as e:
        print(f"Error extracting metadata: {e}")
        return {"duration": "00:00", "thumbnail": None}

def format_duration(seconds):
    """ì´ˆë¥¼ HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    minutes, seconds = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
    return f"{minutes:02d}:{seconds:02d}"

# ì²­í¬ ì—…ë¡œë“œìš© ì„ì‹œ ì €ì¥ì†Œ
chunk_uploads = {}

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "message": "EODI Video Analysis API",
        "status": "running",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.post("/upload/init")
async def init_upload(request: dict):
    """
    ì²­í¬ ì—…ë¡œë“œ ì´ˆê¸°í™”
    """
    filename = request.get("filename")
    file_size = request.get("fileSize")
    total_chunks = request.get("totalChunks")

    if not filename or not file_size or not total_chunks:
        raise HTTPException(status_code=400, detail="í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")

    # í™•ì¥ì ê²€ì¦ (íŒŒì¼ëª…ê³¼ ë¬´ê´€í•˜ê²Œ í™•ì¥ìë§Œ ì²´í¬)
    allowed_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
    file_extension = '.' + filename.lower().split('.')[-1]
    if file_extension not in allowed_extensions:
        raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")

    # íŒŒì¼ í¬ê¸° ì œí•œ (2GB)
    max_size = 2 * 1024 * 1024 * 1024  # 2GB
    if file_size > max_size:
        raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ê°€ 2GBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤")

    # ê³ ìœ  ì—…ë¡œë“œ ID ìƒì„±
    upload_id = str(uuid.uuid4())

    # ì„ì‹œ ì €ì¥ ì •ë³´ ì´ˆê¸°í™”
    chunk_uploads[upload_id] = {
        "filename": filename,
        "file_size": file_size,
        "total_chunks": total_chunks,
        "uploaded_chunks": [],
        "temp_path": os.path.join(TEMP_DIR, f"{upload_id}.tmp"),
        "created_at": datetime.now()
    }

    return {"uploadId": upload_id}

@app.post("/upload/chunk")
async def upload_chunk(
    uploadId: str = Form(...),
    chunkIndex: int = Form(...),
    totalChunks: int = Form(...),
    chunk: UploadFile = File(...)
):
    """
    íŒŒì¼ ì²­í¬ ì—…ë¡œë“œ
    """
    if uploadId not in chunk_uploads:
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì—…ë¡œë“œ IDì…ë‹ˆë‹¤")

    upload_info = chunk_uploads[uploadId]

    # ì²­í¬ ì¸ë±ìŠ¤ ê²€ì¦
    if chunkIndex >= totalChunks or chunkIndex in upload_info["uploaded_chunks"]:
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì²­í¬ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤")

    # ì²­í¬ ë°ì´í„° ì½ê¸°
    chunk_data = await chunk.read()

    try:
        # ì„ì‹œ íŒŒì¼ì— ì²­í¬ ì¶”ê°€
        with open(upload_info["temp_path"], "ab") as temp_file:
            temp_file.write(chunk_data)

        # ì—…ë¡œë“œëœ ì²­í¬ ê¸°ë¡
        upload_info["uploaded_chunks"].append(chunkIndex)

        return {"success": True, "chunkIndex": chunkIndex}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²­í¬ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/upload/complete")
async def complete_upload(request: dict):
    """
    ì²­í¬ ì—…ë¡œë“œ ì™„ë£Œ
    """
    upload_id = request.get("uploadId")

    if not upload_id or upload_id not in chunk_uploads:
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì—…ë¡œë“œ IDì…ë‹ˆë‹¤")

    upload_info = chunk_uploads[upload_id]

    # ëª¨ë“  ì²­í¬ê°€ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if len(upload_info["uploaded_chunks"]) != upload_info["total_chunks"]:
        raise HTTPException(status_code=400, detail="ëª¨ë“  ì²­í¬ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    # ìµœì¢… íŒŒì¼ ê²½ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{timestamp}_{upload_info['filename']}"
    final_path = os.path.join(UPLOAD_DIR, filename)

    try:
        # ì„ì‹œ íŒŒì¼ì„ ìµœì¢… ìœ„ì¹˜ë¡œ ì´ë™
        shutil.move(upload_info["temp_path"], final_path)

        # ì‹¤ì œ íŒŒì¼ í¬ê¸° ê²€ì¦
        actual_size = os.path.getsize(final_path)
        if actual_size != upload_info["file_size"]:
            # í¬ê¸°ê°€ ë§ì§€ ì•Šìœ¼ë©´ íŒŒì¼ ì‚­ì œ
            os.remove(final_path)
            raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥
        video_id = len(videos_db) + 1
        metadata = extract_video_metadata(final_path)
        video_info = {
            "id": video_id,
            "filename": filename,
            "original_name": upload_info["filename"],
            "file_path": final_path,
            "file_size": actual_size,
            "uploaded_at": datetime.now().isoformat(),
            "status": "uploaded",
            "duration": metadata["duration"],
            "thumbnail": metadata["thumbnail"]
        }
        videos_db.append(video_info)

        # ì„ì‹œ ë°ì´í„° ì •ë¦¬
        del chunk_uploads[upload_id]

        return {
            "success": True,
            "message": f"'{upload_info['filename']}' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "video_id": video_id,
            "filename": filename
        }

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(upload_info["temp_path"]):
            os.remove(upload_info["temp_path"])
        del chunk_uploads[upload_id]
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì™„ë£Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ê¸°ì¡´ ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œ (í˜¸í™˜ì„± ìœ ì§€)
@app.post("/upload")
async def upload_video(file: UploadFile = File(...)):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ (ë‹¨ì¼ íŒŒì¼, í˜¸í™˜ì„± ìœ ì§€)
    """
    # í™•ì¥ì ê²€ì¦ (íŒŒì¼ëª…ê³¼ ë¬´ê´€í•˜ê²Œ í™•ì¥ìë§Œ ì²´í¬)
    allowed_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
    file_extension = os.path.splitext(file.filename)[1].lower()
    if file_extension not in allowed_extensions:
        raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")

    # íŒŒì¼ í¬ê¸° ì œí•œ (2GB)
    file_size = 0
    content = await file.read()
    file_size = len(content)

    max_size = 2 * 1024 * 1024 * 1024  # 2GB
    if file_size > max_size:
        raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ê°€ 2GBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤")

    # íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{timestamp}_{file.filename}"
    file_path = os.path.join(UPLOAD_DIR, filename)

    try:
        with open(file_path, "wb") as buffer:
            buffer.write(content)

        # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥
        video_id = len(videos_db) + 1
        metadata = extract_video_metadata(file_path)
        video_info = {
            "id": video_id,
            "filename": filename,
            "original_name": file.filename,
            "file_path": file_path,
            "file_size": file_size,
            "uploaded_at": datetime.now().isoformat(),
            "status": "uploaded",  # uploaded, analyzing, completed, failed
            "analysis_result": None,
            "duration": metadata["duration"],
            "thumbnail": metadata["thumbnail"]
        }

        videos_db.append(video_info)

        return {
            "success": True,
            "message": "ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤",
            "video_id": video_id,
            "filename": filename
        }

    except Exception as e:
        # ì—…ë¡œë“œ ì‹¤íŒ¨ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@app.get("/videos")
async def get_videos():
    """
    ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ
    """
    return {
        "videos": videos_db,
        "total": len(videos_db)
    }

@app.get("/shorts/videos")
async def get_completed_videos():
    """ì‡¼ì¸  ìƒì„±ìš© ë¶„ì„ ì™„ë£Œëœ ë¹„ë””ì˜¤ ëª©ë¡ ë°˜í™˜"""
    completed_videos = []
    
    for video in videos_db:
        if video["status"] == "completed" and "result_file" in video:
            # ê²°ê³¼ íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if os.path.exists(video["result_file"]):
                completed_videos.append({
                    "id": video["id"],
                    "original_name": video["original_name"],
                    "uploaded_at": video["uploaded_at"],
                    "duration": video.get("duration", "00:00"),
                    "thumbnail": video.get("thumbnail"),
                    "result_file": video["result_file"],
                    "total_scenes": video.get("analysis_result", {}).get("total_scenes", 0),
                    "dominant_mood": video.get("analysis_result", {}).get("overall_summary", {}).get("dominant_mood", "unknown"),
                    "shorts_status": video.get("shorts_status", "none"),
                    "shorts_progress": video.get("shorts_progress", 0),
                    "shorts_clips_count": video.get("shorts_clips_count", 0)
                })
    
    return {"videos": completed_videos, "total": len(completed_videos)}

@app.post("/shorts/generate/{video_id}")
async def generate_shorts(video_id: int, background_tasks: BackgroundTasks):
    """ì„ íƒëœ ë¹„ë””ì˜¤ì˜ ì‡¼ì¸  ìƒì„±"""
    # ë¹„ë””ì˜¤ ì°¾ê¸°
    video = next((v for v in videos_db if v["id"] == video_id), None)
    if not video:
        raise HTTPException(status_code=404, detail="ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    if video["status"] != "completed":
        raise HTTPException(status_code=400, detail="ë¶„ì„ì´ ì™„ë£Œëœ ë¹„ë””ì˜¤ë§Œ ì‡¼ì¸  ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    if not video.get("result_file") or not os.path.exists(video["result_file"]):
        raise HTTPException(status_code=400, detail="ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    # ì‡¼ì¸  ìƒì„± ìƒíƒœ ì´ˆê¸°í™”
    video["shorts_status"] = "generating"
    video["shorts_progress"] = 0
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‡¼ì¸  ìƒì„± ì‘ì—… ì‹œì‘
    background_tasks.add_task(perform_shorts_generation, video_id)
    
    return {
        "message": f"'{video['original_name']}' ì‡¼ì¸  ìƒì„±ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.",
        "success": True,
        "video_id": video_id
    }

@app.get("/videos/{video_id}")
async def get_video(video_id: int):
    """
    íŠ¹ì • ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ
    """
    if video_id < 1 or video_id > len(videos_db):
        raise HTTPException(status_code=404, detail="ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return videos_db[video_id - 1]

@app.post("/analyze/{video_id}")
async def analyze_video(video_id: int, background_tasks: BackgroundTasks):
    """
    ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘ (qwen2.5vl:7b ëª¨ë¸ ì‚¬ìš©)
    """
    if video_id < 1 or video_id > len(videos_db):
        raise HTTPException(status_code=404, detail="ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    video = videos_db[video_id - 1]

    if video["status"] == "analyzing":
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ì¤‘ì…ë‹ˆë‹¤")

    # ë¶„ì„ ìƒíƒœë¡œ ë³€ê²½
    video["status"] = "analyzing"
    video["progress"] = 0
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰
    background_tasks.add_task(perform_video_analysis, video_id, video["file_path"])
    
    return {
        "success": True,
        "message": "ë¹„ë””ì˜¤ ë¶„ì„ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤",
        "video_id": video_id,
        "status": "analyzing"
    }

async def preload_ollama_models():
    """Ollama ëª¨ë¸ë“¤ ì‚¬ì „ ë¡œë“œ (2ê°œ ì¸ìŠ¤í„´ìŠ¤)"""
    try:
        logger.info("Ollama ëª¨ë¸ 2ê°œ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ì „ ë¡œë“œ ì¤‘...")
        
        # ì²« ë²ˆì§¸ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ
        payload1 = {
            "model": "qwen2.5vl:7b",
            "prompt": "Initialize model 1",
            "keep_alive": "30m",
            "options": {"num_predict": 1}
        }
        
        # ë‘ ë²ˆì§¸ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ (ì•½ê°„ì˜ ì§€ì—° í›„)
        payload2 = {
            "model": "qwen2.5vl:7b", 
            "prompt": "Initialize model 2",
            "keep_alive": "30m",
            "options": {"num_predict": 1}
        }
        
        # ë³‘ë ¬ë¡œ ë‘ ëª¨ë¸ ë¡œë“œ
        tasks = [
            requests.post("http://127.0.0.1:11434/api/generate", json=payload1, timeout=60),
            requests.post("http://127.0.0.1:11434/api/generate", json=payload2, timeout=60)
        ]
        
        # ìˆœì°¨ ì‹¤í–‰ (ì•ˆì •ì„±ì„ ìœ„í•´)
        for i, payload in enumerate([payload1, payload2], 1):
            try:
                response = requests.post("http://127.0.0.1:11434/api/generate", json=payload, timeout=60)
                if response.status_code == 200:
                    logger.info(f"Ollama ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ {i} ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.warning(f"ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ {i} ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
            except Exception as e:
                logger.warning(f"ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ {i} ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                
        logger.info("ëª¨ë“  Ollama ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        
    except Exception as e:
        logger.warning(f"ëª¨ë¸ ì‚¬ì „ ë¡œë“œ ì¤‘ ì „ì²´ ì˜¤ë¥˜: {e}")

async def perform_video_analysis(video_id: int, video_path: str):
    """ì‹¤ì œ ë¹„ë””ì˜¤ ë¶„ì„ ìˆ˜í–‰"""
    video = videos_db[video_id - 1]
    
    try:
        logger.info(f"ë¹„ë””ì˜¤ {video_id} ë¶„ì„ ì‹œì‘: {video_path}")
        
        # ëª¨ë¸ 2ê°œ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ì „ ë¡œë“œ
        await preload_ollama_models()
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        scene_analyzer = SceneAnalyzer()
        batch_manager = BatchSizeManager()
        
        # 1ë‹¨ê³„: í”„ë ˆì„ ì¶”ì¶œ (1ì´ˆ ê°„ê²©)
        logger.info("í”„ë ˆì„ ì¶”ì¶œ ì‹œì‘...")
        video["progress"] = 10
        frames_data = await scene_analyzer.extract_frames_from_video(video_path, interval_seconds=1)
        
        if not frames_data:
            raise Exception("í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨")
        
        # 2ë‹¨ê³„: ì¥ë©´ ì „í™˜ ê°ì§€
        logger.info("ì¥ë©´ ì „í™˜ ê°ì§€ ì¤‘...")
        video["progress"] = 30
        scene_changes = scene_analyzer.detect_scene_changes(frames_data)
        detected_scenes = scene_analyzer.group_frames_by_scene(frames_data, scene_changes)
        
        # ë°°ì¹˜ í¬ê¸° ê³„ì‚°
        batch_size = batch_manager.get_optimal_batch_size()
        expected_scene_count = max(1, math.ceil(len(frames_data) / batch_size))
        
        # í´ë°± ë¡œì§: ê°ì§€ëœ ì”¬ì´ ê¸°ëŒ€ ì”¬ ìˆ˜ë³´ë‹¤ ì ìœ¼ë©´ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê°•ì œ ë¶„í• 
        if len(detected_scenes) < expected_scene_count:
            logger.info(f"ì”¬ ê°ì§€ ë¶€ì¡± ({len(detected_scenes)} < {expected_scene_count}): ë°°ì¹˜ ë‹¨ìœ„ë¡œ {expected_scene_count}ê°œ ì”¬ ìƒì„±")
            scenes = build_scenes_by_batch(
                frames_data,
                scene_analyzer.interval_seconds,
                scene_analyzer.video_duration,
                batch_size
            )
        else:
            logger.info(f"ì”¬ ê°ì§€ ì¶©ë¶„: {len(detected_scenes)}ê°œ ì”¬ ì‚¬ìš©")
            scenes = detected_scenes
        
        # 3ë‹¨ê³„: ì¥ë©´ë³„ ìˆœì°¨ ë¶„ì„ (ì•ˆì •ì„± ìš°ì„ )
        logger.info("ì¥ë©´ ë¶„ì„ ì‹œì‘...")
        analysis_results = []
        
        total_scenes = len(scenes)
        logger.info(f"ì´ {total_scenes}ê°œ ì¥ë©´ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤...")
        
        # ìˆœì°¨ ë¶„ì„ (ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥)
        for i, scene in enumerate(scenes):
            try:
                logger.info(f"ì¥ë©´ {scene['scene_id']} ë¶„ì„ ì¤‘... ({i+1}/{total_scenes})")
                
                scene_analysis = await scene_analyzer.analyze_scene_batch(
                    scene['frames'],
                    scene['scene_id'], 
                    scene['start_time'],
                    scene['end_time']
                )
                
                analysis_results.append(scene_analysis)
                logger.info(f"ì¥ë©´ {scene['scene_id']} ë¶„ì„ ì™„ë£Œ")
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (30% ~ 90%)
                progress = 30 + int((i + 1) / total_scenes * 60)
                video["progress"] = progress
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                
            except Exception as e:
                logger.error(f"ì¥ë©´ {scene['scene_id']} ë¶„ì„ ì‹¤íŒ¨: {e}")
                fallback_analysis = scene_analyzer.create_fallback_analysis(
                    scene['scene_id'],
                    scene['start_time'], 
                    scene['end_time']
                )
                analysis_results.append(fallback_analysis)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
        # 4ë‹¨ê³„: ì „ì²´ ìš”ì•½ ìƒì„±
        logger.info("ì „ì²´ ë¶„ì„ ìš”ì•½ ìƒì„± ì¤‘...")
        video["progress"] = 90
        
        overall_summary = generate_overall_summary(analysis_results, frames_data)
        
        # 5ë‹¨ê³„: ê²°ê³¼ ì €ì¥
        logger.info("ê²°ê³¼ ì €ì¥ ì¤‘...")
        final_result = {
            "video_id": video_id,
            "analysis_timestamp": datetime.now().isoformat(),
            "total_scenes": len(analysis_results),
            "total_frames": len(frames_data),
            "video_duration": scene_analyzer.video_duration,
            "overall_summary": overall_summary,
            "scene_analysis": analysis_results
        }
        
        # temp/ì˜ìƒíŒŒì¼ëª….jsonì— ì €ì¥
        video_filename = os.path.splitext(video["original_name"])[0]  # í™•ì¥ì ì œê±°
        result_file_path = os.path.join(RESULTS_DIR, f"{video_filename}.json")
        async with aiofiles.open(result_file_path, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(final_result, ensure_ascii=False, indent=2))
        
        # ë¹„ë””ì˜¤ ìƒíƒœ ì—…ë°ì´íŠ¸
        video["status"] = "completed"
        video["progress"] = 100
        video["analysis_result"] = final_result
        video["result_file"] = result_file_path
        
        logger.info(f"ë¹„ë””ì˜¤ {video_id} ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"ë¹„ë””ì˜¤ {video_id} ë¶„ì„ ì‹¤íŒ¨: {e}")
        video["status"] = "failed"
        video["progress"] = 0
        video["error"] = str(e)

async def perform_shorts_generation(video_id: int):
    """ì‡¼ì¸  ìƒì„± ì‘ì—… ìˆ˜í–‰ (ë°±ê·¸ë¼ìš´ë“œ)"""
    try:
        video = next((v for v in videos_db if v["id"] == video_id), None)
        if not video:
            logger.error(f"ì‡¼ì¸  ìƒì„± ì‹¤íŒ¨: ë¹„ë””ì˜¤ {video_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return
        
        logger.info(f"ì‡¼ì¸  ìƒì„± ì‹œì‘: {video['original_name']}")
        
        # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì½ê¸°
        async with aiofiles.open(video["result_file"], 'r', encoding='utf-8') as f:
            analysis_data = json.loads(await f.read())
        
        # í•˜ì´ë¼ì´íŠ¸ ì¥ë©´ ì¶”ì¶œ
        highlight_scenes = []
        for scene in analysis_data.get("scene_analysis", []):
            if scene.get("highlight_score", 0) > 0.7:  # í•˜ì´ë¼ì´íŠ¸ ì ìˆ˜ 0.7 ì´ìƒ
                highlight_scenes.append(scene)
        
        if not highlight_scenes:
            logger.warning(f"í•˜ì´ë¼ì´íŠ¸ ì¥ë©´ì´ ì—†ì–´ì„œ ìƒìœ„ 3ê°œ ì¥ë©´ ì„ íƒ: {video['original_name']}")
            # í•˜ì´ë¼ì´íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒìœ„ 3ê°œ ì¥ë©´ ì„ íƒ
            scenes_by_score = sorted(
                analysis_data.get("scene_analysis", []), 
                key=lambda x: x.get("highlight_score", 0), 
                reverse=True
            )
            highlight_scenes = scenes_by_score[:3]
        
        # ì‡¼ì¸  í´ë¦½ ì •ë³´ ìƒì„±
        shorts_clips = []
        for i, scene in enumerate(highlight_scenes[:5]):  # ìµœëŒ€ 5ê°œ í´ë¦½
            clip_info = {
                "clip_id": i + 1,
                "scene_id": scene.get("scene_id"),
                "start_time": scene.get("time_range", {}).get("start", 0),
                "end_time": scene.get("time_range", {}).get("end", 0),
                "duration": scene.get("time_range", {}).get("duration", 0),
                "description": scene.get("scene_description", ""),
                "mood": scene.get("mood", "neutral"),
                "highlight_score": scene.get("highlight_score", 0)
            }
            shorts_clips.append(clip_info)
        
        # ì‡¼ì¸  ì •ë³´ ì €ì¥
        shorts_result = {
            "video_id": video_id,
            "video_name": video["original_name"],
            "generation_timestamp": datetime.now().isoformat(),
            "total_clips": len(shorts_clips),
            "clips": shorts_clips
        }
        
        # ì‡¼ì¸  ê²°ê³¼ íŒŒì¼ ì €ì¥
        video_filename = os.path.splitext(video["original_name"])[0]
        shorts_file_path = os.path.join(SHORTS_DIR, f"{video_filename}_shorts.json")
        async with aiofiles.open(shorts_file_path, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(shorts_result, ensure_ascii=False, indent=2))
        
        # ì‡¼ì¸  ìƒì„± ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        video["shorts_status"] = "completed"
        video["shorts_progress"] = 100
        video["shorts_file"] = shorts_file_path
        video["shorts_clips_count"] = len(shorts_clips)
        
        logger.info(f"ì‡¼ì¸  ìƒì„± ì™„ë£Œ: {len(shorts_clips)}ê°œ í´ë¦½ - {shorts_file_path}")
        
    except Exception as e:
        logger.error(f"ì‡¼ì¸  ìƒì„± ì‹¤íŒ¨ (ë¹„ë””ì˜¤ {video_id}): {e}")
        
        # ì‡¼ì¸  ìƒì„± ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        video = next((v for v in videos_db if v["id"] == video_id), None)
        if video:
            video["shorts_status"] = "failed"
            video["shorts_progress"] = 0

def build_scenes_by_batch(frames_data: List[Dict], interval_sec: float, video_duration: float, batch_size: int) -> List[Dict]:
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì”¬ì„ ê°•ì œ ìƒì„±"""
    scenes = []
    n = len(frames_data)
    
    for i in range(0, n, batch_size):
        chunk = frames_data[i:i+batch_size]
        start_time = float(chunk[0]['timestamp'])
        
        # ë‹¤ìŒ ë°°ì¹˜ì˜ ì²« í”„ë ˆì„ ì‹œê° (ì—†ìœ¼ë©´ ë¹„ë””ì˜¤ ë)
        next_batch_start = float(frames_data[i+batch_size]['timestamp']) if (i+batch_size) < n else video_duration
        
        # ì¢…ë£Œ ì‹œê°: ë§ˆì§€ë§‰ í”„ë ˆì„ + ê°„ê²©, ë‹¤ìŒ ë°°ì¹˜ ì‹œì‘, ë¹„ë””ì˜¤ ë ì¤‘ ìµœì†Œê°’
        end_time = min(
            float(chunk[-1]['timestamp']) + interval_sec,
            next_batch_start,
            video_duration
        )
        
        # ì‹œì‘ê³¼ ëì´ ê°™ìœ¼ë©´ ìµœì†Œ ê°„ê²© ë³´ì¥
        if end_time <= start_time:
            end_time = min(start_time + interval_sec, video_duration)
            
        scenes.append({
            'scene_id': len(scenes) + 1,
            'start_time': start_time,
            'end_time': end_time,
            'frames': chunk
        })
    
    logger.info(f"ë°°ì¹˜ ë‹¨ìœ„ë¡œ {len(scenes)}ê°œ ì”¬ ìƒì„± (ë°°ì¹˜ í¬ê¸°: {batch_size})")
    return scenes

def generate_overall_summary(analysis_results, frames_data):
    """ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
    try:
        # ë¶„ìœ„ê¸° ë¶„í¬ ê³„ì‚°
        mood_counts = {}
        highlight_scenes = []
        total_highlight_score = 0
        
        for result in analysis_results:
            mood = result.get('mood', 'unknown')
            mood_counts[mood] = mood_counts.get(mood, 0) + 1
            
            highlight_score = result.get('highlight_score', 0)
            total_highlight_score += highlight_score
            
            if highlight_score > 0.7:
                highlight_scenes.append(result)
        
        # ì£¼ìš” ë¶„ìœ„ê¸° ê²°ì •
        dominant_mood = max(mood_counts, key=mood_counts.get) if mood_counts else 'unknown'
        
        return {
            "dominant_mood": dominant_mood,
            "mood_distribution": mood_counts,
            "total_scenes": len(analysis_results),
            "highlight_scenes": len(highlight_scenes),
            "average_highlight_score": total_highlight_score / len(analysis_results) if analysis_results else 0,
            "recommended_clips": highlight_scenes[:5],  # ìƒìœ„ 5ê°œ í•˜ì´ë¼ì´íŠ¸
            "analysis_quality": "good" if len([r for r in analysis_results if not r.get('error', False)]) > len(analysis_results) * 0.8 else "fair"
        }
        
    except Exception as e:
        logger.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return {
            "dominant_mood": "unknown",
            "mood_distribution": {},
            "total_scenes": len(analysis_results),
            "highlight_scenes": 0,
            "average_highlight_score": 0,
            "recommended_clips": [],
            "analysis_quality": "error"
        }

@app.post("/generate-shorts/{video_id}")
async def generate_shorts(video_id: int, criteria: Dict[str, Any] = None):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‡¼ì¸  ìƒì„±
    """
    if video_id < 1 or video_id > len(videos_db):
        raise HTTPException(status_code=404, detail="ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    video = videos_db[video_id - 1]

    if video["status"] != "completed":
        raise HTTPException(status_code=400, detail="ë¨¼ì € ë¹„ë””ì˜¤ ë¶„ì„ì„ ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤")

    try:
        # TODO: ì‹¤ì œ ì‡¼ì¸  ìƒì„± ë¡œì§ êµ¬í˜„
        # 1. ë¶„ì„ ê²°ê³¼ì—ì„œ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ
        # 2. FFmpegìœ¼ë¡œ í´ë¦½ ìƒì„±
        # 3. ê²°ê³¼ ì €ì¥

        # ì„ì‹œ ì‘ë‹µ (ì‹¤ì œ êµ¬í˜„ì‹œ ì œê±°)
        shorts_result = {
            "shorts_generated": 3,
            "clips": [
                {
                    "id": 1,
                    "start_time": "00:00:05",
                    "end_time": "00:00:15",
                    "mood": "excited",
                    "description": "ê°€ì¥ ì‹ ë‚˜ëŠ” ë¶€ë¶„"
                },
                {
                    "id": 2,
                    "start_time": "00:01:20",
                    "end_time": "00:01:30",
                    "mood": "happy",
                    "description": "ì›ƒìŒì´ ë§ì€ ë¶€ë¶„"
                },
                {
                    "id": 3,
                    "start_time": "00:03:45",
                    "end_time": "00:03:55",
                    "mood": "emotional",
                    "description": "ê°ì •ì ì¸ ë¶€ë¶„"
                }
            ]
        }

        return {
            "success": True,
            "message": "ì‡¼ì¸  ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "video_id": video_id,
            "shorts_result": shorts_result
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì‡¼ì¸  ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.delete("/videos/{video_id}")
async def delete_video(video_id: int):
    """
    ë¹„ë””ì˜¤ ë° ê´€ë ¨ íŒŒì¼ ì‚­ì œ
    """
    if video_id < 1 or video_id > len(videos_db):
        raise HTTPException(status_code=404, detail="ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    video = videos_db[video_id - 1]

    try:
        # íŒŒì¼ ì‚­ì œ
        if os.path.exists(video["file_path"]):
            os.remove(video["file_path"])

        # ë¶„ì„ ê²°ê³¼ ì‚­ì œ (ìˆëŠ” ê²½ìš°)
        if video["analysis_result"]:
            result_file = os.path.join(ANALYSIS_DIR, f"analysis_{video_id}.json")
            if os.path.exists(result_file):
                os.remove(result_file)

        # ëª©ë¡ì—ì„œ ì œê±°
        videos_db.pop(video_id - 1)

        return {
            "success": True,
            "message": "ë¹„ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

# ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "error": exc.detail,
            "timestamp": datetime.now().isoformat()
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            "detail": str(exc),
            "timestamp": datetime.now().isoformat()
        }
    )

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="127.0.0.1",
        port=8000,
        reload=False,  # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ë¦¬ë¡œë“œ ë¹„í™œì„±í™”
        log_level="info"
    )
