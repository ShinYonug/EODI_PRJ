const { app, BrowserWindow, ipcMain } = require('electron');
const path = require('path');
const { spawn, exec } = require('child_process');
const fs = require('fs');
const os = require('os');
const http = require('http');

let mainWindow;
let ollamaProcess = null;

// OSë³„ Ollama ê²½ë¡œ ì„¤ì •
function getOllamaPaths() {
  const platform = os.platform();
  const homeDir = os.homedir();

  if (platform === 'win32') {
    // Windows: C:\EODI í´ë”
    return {
      installPath: 'C:\\EODI\\ollama',
      exePath: 'C:\\EODI\\ollama\\ollama.exe',
      checkCommand: 'where ollama',
      commonPaths: ['C:\\EODI\\ollama\\ollama.exe']
    };
  } else if (platform === 'darwin') {
    // macOS: Homebrew ê²½ë¡œ ìš°ì„  í™•ì¸
    return {
      installPath: '/opt/homebrew/bin/ollama',
      exePath: '/opt/homebrew/bin/ollama',
      checkCommand: 'which ollama',
      commonPaths: [
        '/opt/homebrew/bin/ollama',  // Homebrew ê²½ë¡œ
        path.join(homeDir, 'Desktop', 'ollama', 'ollama'),  // Desktop ê²½ë¡œ
        '/usr/local/bin/ollama'  // ê¸°ë³¸ ê²½ë¡œ
      ]
    };
  } else {
    // Linux ë“± ë‹¤ë¥¸ OS
    return {
      installPath: '/usr/local/bin/ollama',
      exePath: '/usr/local/bin/ollama',
      checkCommand: 'which ollama',
      commonPaths: ['/usr/local/bin/ollama']
    };
  }
}

// Ollama ì„¤ì¹˜ ìƒíƒœ í™•ì¸
function checkOllamaInstalled() {
  return new Promise((resolve) => {
    const paths = getOllamaPaths();

    // 1. PATHì—ì„œ ì‹¤í–‰ í™•ì¸
    exec('ollama --version 2>&1', (error, stdout, stderr) => {
      console.log('ollama --version result:', { error: error?.code, stdout: stdout.trim(), stderr: stderr.trim() });

      // stderrì— ë²„ì „ ì •ë³´ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
      const output = stdout + stderr;
      if (output.includes('client version is') || (!error && output.trim())) {
        console.log('Ollama is installed and working');
        resolve(true);
        return;
      }

      // 2. ì§€ì •ëœ exePath í™•ì¸
      fs.access(paths.exePath, fs.constants.F_OK, (err) => {
        if (!err) {
          console.log('Ollama found at:', paths.exePath);
          resolve(true);
        } else {
          console.log('Ollama not found');
          resolve(false);
        }
      });
    });
  });
}

// Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸ (ìˆ˜ì •ëœ í•¨ìˆ˜)
function checkOllamaServerRunning() {
  return new Promise((resolve) => {
    exec('curl -s http://localhost:11434/api/tags', (error, stdout) => {
      if (error) {
        console.log('Ollama server not running');
        resolve(false);
        return;
      }

      try {
        JSON.parse(stdout);
        console.log('Ollama server is already running');
        resolve(true);
      } catch (e) {
        console.log('Ollama server response invalid');
        resolve(false);
      }
    });
  });
}

// Ollama ì„¤ì¹˜
function installOllama() {
  return new Promise((resolve, reject) => {
    console.log('Installing Ollama...');

    const platform = os.platform();

    if (platform === 'darwin') {
      // macOS: Homebrewë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ì¹˜
      console.log('Installing Ollama via Homebrew on macOS...');

      const installProcess = spawn('brew', ['install', 'ollama'], {
        stdio: 'pipe'
      });

      let hasError = false;

      installProcess.stdout.on('data', (data) => {
        const output = data.toString();
        console.log('Brew stdout:', output);

        // ì„¤ì¹˜ ì™„ë£Œ ë©”ì‹œì§€ í™•ì¸
        if (output.includes('ğŸº') && output.includes('ollama')) {
          console.log('Ollama installation completed on macOS');
          resolve(true);
        }
      });

      installProcess.stderr.on('data', (data) => {
        const output = data.toString();
        console.log('Brew stderr:', output);

        // ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
        if (output.includes('Error') || output.includes('failed') || output.includes('locked')) {
          hasError = true;
        }
      });

      installProcess.on('close', (code) => {
        if (code === 0 && !hasError) {
          console.log('Ollama installation process completed successfully');
          resolve(true);
        } else {
          console.error(`Ollama installation failed with code ${code}`);
          resolve(false);
        }
      });

      installProcess.on('error', (error) => {
        console.error('Brew install error:', error);
        resolve(false);
      });

    } else if (platform === 'win32') {
      // Windows: ê³µì‹ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
      const installProcess = spawn('powershell', [
        '-Command',
        'Invoke-WebRequest -Uri "https://ollama.ai/download/OllamaSetup.exe" -OutFile "$env:TEMP\\OllamaSetup.exe"; Start-Process -FilePath "$env:TEMP\\OllamaSetup.exe" -ArgumentList "/S" -Wait'
      ], {
        stdio: 'inherit'
      });

      installProcess.on('close', (code) => {
        if (code === 0) {
          console.log('Ollama installation completed on Windows');
          resolve(true);
        } else {
          console.error(`Ollama installation failed with code ${code}`);
          resolve(false);
        }
      });

      installProcess.on('error', (error) => {
        console.error('Windows install error:', error);
        resolve(false);
      });

    } else {
      // Linux: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
      const installProcess = spawn('curl', ['-fsSL', 'https://ollama.ai/install.sh', '|', 'sh'], {
        stdio: 'inherit',
        shell: true
      });

      installProcess.on('close', (code) => {
        if (code === 0) {
          console.log('Ollama installation completed on Linux');
          resolve(true);
        } else {
          console.error(`Ollama installation failed with code ${code}`);
          resolve(false);
        }
      });

      installProcess.on('error', (error) => {
        console.error('Linux install error:', error);
        resolve(false);
      });
    }
  });
}

// Ollama ì„œë²„ ì‹œì‘
function startOllamaServer() {
  return new Promise(async (resolve, reject) => {
    console.log('Checking Ollama server status...');

    // ë¨¼ì € ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
    const isRunning = await checkOllamaServerRunning();
    if (isRunning) {
      console.log('Ollama server is already running, verifying connection...');

      // ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ë¼ë„ ì—°ê²°ì´ ì œëŒ€ë¡œ ë˜ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
      let retries = 0;
      const maxRetries = 3;

      const verifyConnection = () => {
        checkOllamaServerRunning().then((stillRunning) => {
          if (stillRunning) {
            console.log('Ollama server connection verified');
            resolve();
          } else if (retries < maxRetries) {
            retries++;
            console.log(`Server connection check failed, retry ${retries}/${maxRetries}`);
            setTimeout(verifyConnection, 2000);
          } else {
            console.log('Server connection verification failed, starting new server');
            startNewServer();
          }
        }).catch(() => {
          if (retries < maxRetries) {
            retries++;
            console.log(`Server connection check failed, retry ${retries}/${maxRetries}`);
            setTimeout(verifyConnection, 2000);
          } else {
            console.log('Server connection verification failed, starting new server');
            startNewServer();
          }
        });
      };

      verifyConnection();
      return;
    }

    // ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œ ì‹œì‘
    startNewServer();

    function startNewServer() {
      console.log('Starting new Ollama server with optimized settings...');

      const paths = getOllamaPaths();

    // PATHì— ìˆëŠ” ollama ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì§€ì •ëœ ê²½ë¡œ ì‚¬ìš©
    exec('which ollama', (error, stdout) => {
      const ollamaCmd = error ? paths.exePath : 'ollama';

      // M4 Max ìµœì í™”ëœ Ollama í™˜ê²½ë³€ìˆ˜ ì„¤ì •
      const optimizedEnv = {
        ...process.env,
        OLLAMA_NUM_PARALLEL: '1',           // ë‹¨ì¼ ëª¨ë¸ ì „ìš© (ìˆœì°¨ ì²˜ë¦¬)
        OLLAMA_MAX_LOADED_MODELS: '1',      // ëª¨ë¸ 1ê°œë§Œ ë¡œë“œ
        OLLAMA_FLASH_ATTENTION: '1',        // Flash Attention í™œì„±í™”
        OLLAMA_NUM_GPU: '40',               // M4 Max 40ê°œ GPU ì½”ì–´ ëª…ì‹œì  ì‚¬ìš©
        OLLAMA_KEEP_ALIVE: '15m',           // ëª¨ë¸ 15ë¶„ê°„ ë©”ëª¨ë¦¬ ìœ ì§€
        OLLAMA_GPU_LAYERS: '99',            // ëª¨ë“  ë ˆì´ì–´ë¥¼ GPUì—ì„œ ì²˜ë¦¬
        OLLAMA_LOAD_TIMEOUT: '300',         // ë¡œë“œ íƒ€ì„ì•„ì›ƒ 5ë¶„
        OLLAMA_GPU_MEMORY_FRACTION: '0.9',  // í†µí•© ë©”ëª¨ë¦¬ 90% ì‚¬ìš©
        OLLAMA_MAX_QUEUE: '5',              // ëŒ€ê¸°ì—´ í¬ê¸° (ë‹¨ì¼ ëª¨ë¸ìš©)
        OLLAMA_CONTEXT_LENGTH: '8192'       // ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì„¤ì •
      };

      console.log('Ollama environment variables:', {
        OLLAMA_NUM_PARALLEL: optimizedEnv.OLLAMA_NUM_PARALLEL,
        OLLAMA_MAX_LOADED_MODELS: optimizedEnv.OLLAMA_MAX_LOADED_MODELS,
        OLLAMA_GPU_MEMORY_FRACTION: optimizedEnv.OLLAMA_GPU_MEMORY_FRACTION
      });

      ollamaProcess = spawn(ollamaCmd, ['serve'], {
        stdio: ['ignore', 'pipe', 'pipe'],
        detached: false,
        env: optimizedEnv  // ìµœì í™”ëœ í™˜ê²½ë³€ìˆ˜ ì ìš©
      });

      let serverReady = false;

      const checkServerReady = (data) => {
        const output = data.toString();
        console.log('Ollama output:', output);

        if ((output.includes('listening on') || output.includes('Listening on')) && !serverReady) {
          serverReady = true;
          console.log('Ollama server is ready');
          resolve();
        }
      };

      ollamaProcess.stdout.on('data', checkServerReady);
      ollamaProcess.stderr.on('data', checkServerReady);

      ollamaProcess.on('close', (code) => {
        console.log(`Ollama process exited with code ${code}`);
        if (!serverReady) {
          reject(new Error('Ollama server failed to start'));
        }
      });

      ollamaProcess.on('error', (error) => {
        console.error('Failed to start Ollama:', error);
        reject(error);
      });

      // íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ì´ˆ)
      setTimeout(() => {
        if (!serverReady) {
          ollamaProcess.kill();
          reject(new Error('Ollama server startup timeout'));
        }
      }, 600000);
    });
  }});
}

// qwen2.5-vl-7b ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
function checkModelLoaded() {
  return new Promise((resolve) => {
    exec('curl -s http://localhost:11434/api/tags', (error, stdout) => {
      if (error) {
        resolve(false);
        return;
      }

      try {
        const response = JSON.parse(stdout);
        const hasModel = response.models && response.models.some(model =>
          model.name.includes('qwen2.5vl:7b')
        );
        resolve(hasModel);
      } catch (e) {
        resolve(false);
      }
    });
  });
}

// qwen2.5vl:7b ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (spawn ì‚¬ìš©ìœ¼ë¡œ ë²„í¼ ë¬¸ì œ í•´ê²°)
function downloadModel() {
  return new Promise((resolve, reject) => {
    console.log('Downloading qwen2.5vl:7b model...');

    const downloadProcess = spawn('ollama', ['pull', 'qwen2.5vl:7b'], {
      stdio: ['ignore', 'pipe', 'pipe']
    });

    let completed = false;

    downloadProcess.stdout.on('data', (data) => {
      const output = data.toString();
      console.log('Download stdout:', output);

      // ì§„í–‰ë¥  íŒŒì‹± ë° ì „ì†¡
      const progressMatch = output.match(/(\d+)%/);
      if (progressMatch) {
        const progress = parseInt(progressMatch[1]);
        mainWindow.webContents.send('download-progress', { progress, message: `ë‹¤ìš´ë¡œë“œ ì¤‘... ${progress}%` });
      }

      // ë‹¤ìš´ë¡œë“œ ë‹¨ê³„ í‘œì‹œ
      if (output.includes('pulling manifest')) {
        mainWindow.webContents.send('download-progress', { progress: 5, message: 'ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...' });
      } else if (output.includes('pulling') && output.includes('GB')) {
        mainWindow.webContents.send('download-progress', { progress: 30, message: 'ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...' });
      } else if (output.includes('verifying')) {
        mainWindow.webContents.send('download-progress', { progress: 95, message: 'íŒŒì¼ ê²€ì¦ ì¤‘...' });
      }
    });

    downloadProcess.stderr.on('data', (data) => {
      const output = data.toString();
      console.log('Download stderr:', output);

      // ì„±ê³µ ì™„ë£Œ ë©”ì‹œì§€ í™•ì¸
      if (output.includes('success') || output.includes('complete')) {
        completed = true;
        console.log('Model download completed');
        mainWindow.webContents.send('download-progress', { progress: 100, message: 'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!' });
        resolve();
      }

      // ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
      if (output.includes('Error:') || output.includes('failed')) {
        console.error('Download error:', output);
        mainWindow.webContents.send('download-progress', { progress: -1, message: 'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ' + output });
        if (!completed) {
          reject(new Error(output));
        }
      }
    });

    downloadProcess.on('close', (code) => {
      console.log(`Download process exited with code ${code}`);
      if (!completed) {
        if (code === 0) {
          // ì •ìƒ ì¢…ë£Œ
          console.log('Model download completed successfully');
          mainWindow.webContents.send('download-progress', { progress: 100, message: 'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!' });
          resolve();
        } else {
          reject(new Error(`Download process exited with code ${code}`));
        }
      }
    });

    downloadProcess.on('error', (error) => {
      console.error('Download process error:', error);
      reject(error);
    });
  });
}

// Ollama ì´ˆê¸°í™” (ì„¤ì¹˜ í™•ì¸ â†’ ì„¤ì¹˜ â†’ ì„œë²„ ì‹œì‘ â†’ ëª¨ë¸ í™•ì¸ â†’ ë‹¤ìš´ë¡œë“œ)
async function initializeOllama() {
  try {
    console.log('Initializing Ollama...');

    // 1. Ollama ì„¤ì¹˜ ìƒíƒœ í™•ì¸
    const isInstalled = await checkOllamaInstalled();
    if (!isInstalled) {
      console.log('Ollama not found, installing...');
      mainWindow.webContents.send('ollama-status', { status: 'installing', message: 'Ollama ì„¤ì¹˜ ì¤‘...' });
      await installOllama();
    }

    // 2. Ollama ì„œë²„ ì‹œì‘
    mainWindow.webContents.send('ollama-status', { status: 'starting', message: 'Ollama ì„œë²„ ì‹œì‘ ì¤‘...' });
    await startOllamaServer();

    // 3. ëª¨ë¸ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
    const modelLoaded = await checkModelLoaded();
    if (!modelLoaded) {
      console.log('Model not found, downloading...');
      mainWindow.webContents.send('ollama-status', { status: 'downloading', message: 'qwen2.5-vl-7b ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...' });
      await downloadModel();
    }

    console.log('Ollama initialization completed');
    mainWindow.webContents.send('ollama-status', { status: 'ready', message: 'Ollama ë° ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ' });

  } catch (error) {
    console.error('Ollama initialization failed:', error);
    mainWindow.webContents.send('ollama-status', {
      status: 'error',
      message: `Ollama ì´ˆê¸°í™” ì‹¤íŒ¨: ${error.message}`
    });
  }
}

async function createWindow() {
  // ë¸Œë¼ìš°ì € ì°½ ìƒì„±
  mainWindow = new BrowserWindow({
    width: 1200,
    height: 800,
    webPreferences: {
      nodeIntegration: true,
      contextIsolation: false,
      enableRemoteModule: true
    },
    icon: path.join(__dirname, 'assets/icon.png'), // ì•„ì´ì½˜ ê²½ë¡œ (ë‚˜ì¤‘ì— ì¶”ê°€)
    titleBarStyle: 'default',
    show: false
  });

  // HTML íŒŒì¼ ë¡œë“œ
  mainWindow.loadFile(path.join(__dirname, 'renderer/index.html'));

  // ì°½ì´ ì¤€ë¹„ë˜ë©´ í‘œì‹œ
  mainWindow.once('ready-to-show', () => {
    mainWindow.show();
  });

  // ê°œë°œì ë„êµ¬ ì—´ê¸° (ê°œë°œ ì‹œì—ë§Œ)
  if (process.env.NODE_ENV === 'development') {
    mainWindow.webContents.openDevTools();
  }

  // ì°½ì´ ë‹«í ë•Œ
  mainWindow.on('closed', () => {
    mainWindow = null;
  });
  // ë Œë”ëŸ¬ê°€ ë¡œë“œëœ í›„ ì´ˆê¸°í™”(ì´ë²¤íŠ¸ ë¯¸ìˆ˜ì‹  ë°©ì§€)
  mainWindow.webContents.once('did-finish-load', async () => {
    try {
      await startBackendIfNeeded();
      const installed = await checkOllamaInstalled();
      if (installed) {
        let running = await checkOllamaServerRunning();
        if (!running) {
          await startOllamaServer();
          running = true;
        }
        const modelReady = running ? await checkModelLoaded() : false;
        if (modelReady) {
          mainWindow.webContents.send('ollama-status', { status: 'ready', message: 'ëª¨ë‘ ì¤€ë¹„ë¨' });
        } else {
          mainWindow.webContents.send('ollama-status', { status: 'ready', message: 'Ollama ì¤€ë¹„ë¨ (ëª¨ë¸ í•„ìš”)' });
        }
      } else {
        mainWindow.webContents.send('ollama-status', { status: 'error', message: 'Ollama ì„¤ì¹˜ í•„ìš”' });
      }
    } catch (e) {
      console.error('Startup init failed:', e);
      mainWindow.webContents.send('ollama-status', { status: 'error', message: 'ì´ˆê¸°í™” ì‹¤íŒ¨' });
    }
  });
}

// ê°œë°œëª¨ë“œì—ì„œë§Œ ë°±ì—”ë“œ ê¸°ë™ (í”„ë¡œë•ì…˜ì€ ë²ˆë“¤ëœ ë°”ì´ë„ˆë¦¬ ì‚¬ìš© ê°€ì •)
let backendProcess = null;
async function startBackendIfNeeded() {
  console.log('startBackendIfNeeded');
  // ê°œë°œ ëª¨ë“œì—ì„œë§Œ ìë™ ê¸°ë™
  const isDev = process.env.NODE_ENV === 'development';
  if (!isDev) {
    console.log('Skipping backend auto-start (NODE_ENV != development)');
    return;
  }
  if (backendProcess) {
    console.log('Backend already running (cached process)');
    return;
  }

  // í›„ë³´ ì‹¤í–‰ ê²½ë¡œë“¤ (ìˆœì„œëŒ€ë¡œ ì‹œë„)
  const projectRoot = path.join(__dirname, '..');
  const venvPython = path.join(projectRoot, 'backend', 'venv', 'bin', 'python');
  const backendPath = path.join(projectRoot, 'backend', 'main.py');

  const candidates = [];
  // macOS/Linux venv
  candidates.push({ cmd: venvPython, args: [backendPath], label: 'venv python' });
  // ì‹œìŠ¤í…œ python3
  candidates.push({ cmd: 'python3', args: [backendPath], label: 'python3' });
  // ì‹œìŠ¤í…œ python
  candidates.push({ cmd: 'python', args: [backendPath], label: 'python' });

  let started = false;
  for (const c of candidates) {
    try {
      console.log(`Trying backend start with ${c.label}: ${c.cmd} ${c.args.join(' ')}`);
      backendProcess = spawn(c.cmd, c.args, { stdio: 'ignore', detached: false });
      console.log('Backend started with', c.label);
      started = true;
      break;
    } catch (e) {
      console.error(`Failed with ${c.label}:`, e);
    }
  }

  if (!started) {
    console.error('All backend start attempts failed.');
  }
}

// ì•±ì´ ì¤€ë¹„ë˜ë©´ ì°½ ìƒì„±
app.whenReady().then(async () => {
  await createWindow();
});

// ëª¨ë“  ì°½ì´ ë‹«í˜”ì„ ë•Œ ì•± ì¢…ë£Œ (macOS ì œì™¸)
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit();
  }
});

// ì•± ì¢…ë£Œ ì „ì— Ollama í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
app.on('before-quit', () => {
  console.log('Shutting down Ollama...');
  if (ollamaProcess) {
    ollamaProcess.kill();
    ollamaProcess = null;
  }
});

// macOSì—ì„œ ì•± ì•„ì´ì½˜ í´ë¦­ì‹œ ì°½ ì¬ìƒì„±
app.on('activate', () => {
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// IPC í†µì‹  í•¸ë“¤ëŸ¬ë“¤ (ë‚˜ì¤‘ì— ë°±ì—”ë“œì™€ í†µì‹ í•  ë•Œ ì‚¬ìš©)
ipcMain.handle('get-video-list', async () => {
  return new Promise((resolve, reject) => {
    const options = {
      hostname: '127.0.0.1',
      port: 8000,
      path: '/videos',
      method: 'GET'
    };

    const req = http.request(options, (res) => {
      let data = '';

      res.on('data', (chunk) => {
        data += chunk;
      });

      res.on('end', () => {
        try {
          const response = JSON.parse(data);
          console.log('Video list from backend:', response);
          resolve(response.videos || []);
        } catch (error) {
          console.error('Error parsing video list:', error);
          resolve([]);
        }
      });
    });

    req.on('error', (error) => {
      console.error('Error fetching video list:', error);
      resolve([]);
    });

    req.end();
  });
});

ipcMain.handle('analyze-video', async (event, videoId) => {
  return new Promise((resolve) => {
    console.log(`Starting video analysis for video ID: ${videoId}`);
    
    const postData = JSON.stringify({});
    
    const options = {
      hostname: '127.0.0.1',
      port: 8000,
      path: `/analyze/${videoId}`,
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Content-Length': Buffer.byteLength(postData)
      }
    };

    const req = http.request(options, (res) => {
      let data = '';

      res.on('data', (chunk) => {
        data += chunk;
      });

      res.on('end', () => {
        try {
          if (res.statusCode === 200) {
            const result = JSON.parse(data);
            console.log('Video analysis started:', result);
            
            resolve({
              success: true,
              message: result.message || 'ë¹„ë””ì˜¤ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
              video_id: videoId,
              status: result.status
            });
          } else {
            console.error(`HTTP error! status: ${res.statusCode}`);
            resolve({
              success: false,
              message: `ì„œë²„ ì˜¤ë¥˜: ${res.statusCode}`
            });
          }
        } catch (error) {
          console.error('Failed to parse analysis response:', error);
          resolve({
            success: false,
            message: 'ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'
          });
        }
      });
    });

    req.on('error', (error) => {
      console.error('Failed to start video analysis:', error);
      resolve({
        success: false,
        message: error.message || 'ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'
      });
    });

    req.write(postData);
    req.end();
  });
});

ipcMain.handle('generate-shorts', async (event, videoId) => {
  // TODO: ì‡¼ì¸  ìƒì„±
  console.log('Generate shorts for video:', videoId);
  return { success: true, message: 'ì‡¼ì¸  ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.' };
});

// Ollama ìƒíƒœ í™•ì¸ í•¸ë“¤ëŸ¬
ipcMain.handle('check-ollama-status', async () => {
  try {
    const ollamaInstalled = await checkOllamaInstalled();
    let serverRunning = await checkOllamaServerRunning();
    if (!serverRunning) {
      serverRunning = await startOllamaServer();
    }
    const modelReady = serverRunning ? await checkModelLoaded() : false;

    return {
      ollamaInstalled,
      serverRunning,
      modelReady
    };
  } catch (error) {
    console.error('Failed to check Ollama status:', error);
    return {
      ollamaInstalled: false,
      serverRunning: false,
      modelReady: false,
      error: error.message
    };
  }
});

// ëª¨ë¸ ìƒíƒœ í™•ì¸ í•¸ë“¤ëŸ¬
ipcMain.handle('check-model-status', async () => {
  try {
    const serverRunning = await checkOllamaServerRunning();
    const modelReady = serverRunning ? await checkModelLoaded() : false;

    return { modelReady };
  } catch (error) {
    console.error('Failed to check model status:', error);
    return { modelReady: false, error: error.message };
  }
});

// Ollama ì„¤ì¹˜ í•¸ë“¤ëŸ¬
ipcMain.handle('install-ollama', async () => {
  try {
    console.log('Installing Ollama...');
    mainWindow.webContents.send('ollama-status', { status: 'installing', message: 'Ollama ì„¤ì¹˜ ì¤‘...' });

    const installResult = await installOllama();

    if (!installResult) {
      throw new Error('Ollama installation failed');
    }

    // ì„¤ì¹˜ ì„±ê³µ í›„ ì„œë²„ ìƒíƒœ í™•ì¸ ë° ì‹œì‘
    mainWindow.webContents.send('ollama-status', { status: 'starting', message: 'Ollama ì„œë²„ ì‹œì‘ ì¤‘...' });

    const serverRunning = await checkOllamaServerRunning();
    if (!serverRunning) {
      await startOllamaServer();
    } else {
      console.log('Ollama server is already running');
    }

    mainWindow.webContents.send('ollama-status', { status: 'ready', message: 'Ollama ì¤€ë¹„ë¨' });
    return { success: true };
  } catch (error) {
    console.error('Ollama installation failed:', error);
    mainWindow.webContents.send('ollama-status', { status: 'error', message: 'Ollama ì„¤ì¹˜ ì‹¤íŒ¨' });
    return { success: false, error: error.message };
  }
});

// ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•¸ë“¤ëŸ¬
ipcMain.handle('download-model', async () => {
  try {
    console.log('Downloading qwen2.5vl:7b model...');
    mainWindow.webContents.send('ollama-status', { status: 'downloading', message: 'qwen2.5vl:7b ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...' });

    await downloadModel();

    mainWindow.webContents.send('ollama-status', { status: 'ready', message: 'ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ' });
    return { success: true };
  } catch (error) {
    console.error('Model download failed:', error);
    return { success: false, error: error.message };
  }
});
